{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e29e6fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dad75c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMMBED_SERVICE_URL = \"http://localhost:8005\"\n",
    "DATABASE_SERVICE_URL = \"http://localhost:8002\"\n",
    "DATA_FILE = './data/Dọn dẹp buồng phòng_structured.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "295e6417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['- Giới thiệu chung\\nDịch vụ Dọn dẹp Buồng phòng của bTaskee- Giải pháp dọn dẹp nhanh chóng và tiện lợi cho chủ các hệ thống khách sạn, homestay, căn hộ dịch vụ, villa, nhà nguyên căn. Đăng lịch với 60 giây và chỉ cần từ 5 phút để có người giúp việc theo giờ nhận việc. Cần lúc nào đặt lịch lúc đó nên có thể giảm chi phí thuê và đào tạo nhân sự cố định. Các nhân viên buồng phòng của bTaskee được sàng lọc kỹ càng, phải có ít nhất 1 năm kinh nghiệm làm việc tại khách sạn 3 sao trở lên. Giá dịch vụ sẽ được hiển thị chi tiết trên ứng dụng. Người dùng không phải trả thêm bất kì phí phát sinh nào.',\n",
       " '\\n- Hướng dẫn sử dụng\\nHướng dẫn đặt dịch vụ dọn dẹp buồng phòng\\nBước 1: Chọn địa chỉ cần đặt lịch\\nBước 2: Chọn loại hình nhà và loại hình phòng.\\nBước 3: Chọn số lượng phòng cần dọn dẹp\\nBước 4: Chọn các dịch vụ thêm( dọn sảnh, setup theo hình,..)\\nBước 5: Chọn ngày giờ làm việc và ghi chú công việc\\nBước 6: Xác nhận và thanh toán\\nBước 7: Đặt lịch',\n",
       " '\\n- Lưu ý\\n- Được chọn cùng lúc nhiều loại phòng, nhưng tối đa là 10 phòng cho mỗi loại phòng.\\n- Mỗi phòng sẽ có thời lượng dọn dẹp khác nhau, nhưng tổng thời lượng công việc tối đa là 6 giờ.\\n- Phụ thu thêm phí hóa chất dọn dẹp:\\n- 30.000vnd nếu thời lượng làm việc >= 3 giờ (3h và 4h)\\n- 50.000vnd nếu thời lượng làm việc >= 5 giờ (5h và 6h)\\n- Đối với Khung giờ cao điểm (trước 8h00 và sau 19h00) và Thứ 7, Chủ Nhật giá dịch vụ tăng 20%.\\n- Giá mang tính chất tham khảo ở thời điểm hiện tại. Giá dịch vụ có thể tự động điều chỉnh tùy vào khu vực, giờ cao điểm, lễ tết.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(DATA_FILE, 'r', encoding='utf-8') as file:\n",
    "    data = file.read().split(\"\\n\\n\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf6640b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcessingPipeline:\n",
    "    def __init__(self):\n",
    "        self.documents = []\n",
    "        self.payloads = []\n",
    "    \n",
    "    def embed_text(self, text: str) -> list:\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                EMMBED_SERVICE_URL + \"/embed\", \n",
    "                json={\"text\": text},\n",
    "                timeout=30\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            return response.json()[\"embedding\"]\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Lỗi embed: {e}\")\n",
    "            raise\n",
    "\n",
    "    def upsert_document(self, payload: dict) -> bool:\n",
    "        try:\n",
    "            # ✅ Wrap payload trong \"points\" array\n",
    "            request_data = {\n",
    "                \"points\": [payload]  # API mong đợi array of points\n",
    "            }\n",
    "            \n",
    "            response = requests.post(\n",
    "                DATABASE_SERVICE_URL + \"/upsert\", \n",
    "                json=request_data,  # Gửi request_data thay vì payload\n",
    "                timeout=30\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            return response.json().get(\"success\", False)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Lỗi upsert: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def process(self, data):\n",
    "        print(f\"🚀 Bắt đầu xử lý {len(data)} documents...\")\n",
    "        \n",
    "        # Bước 1: Tạo embeddings và payloads\n",
    "        for i, document in enumerate(data):\n",
    "            try:\n",
    "                print(f\"📄 Processing {i+1}/{len(data)}: {str(document)[:50]}...\")\n",
    "                \n",
    "                embedding = self.embed_text(str(document))\n",
    "                \n",
    "                payload = {\n",
    "                    \"id\": str(uuid.uuid4()),\n",
    "                    \"vector\": embedding,\n",
    "                    \"payload\": {\n",
    "                        \"text\": str(document),\n",
    "                        \"user_id\": \"test_user\",\n",
    "                        \"title\": \"Dọn dẹp buồng phòng_structured.txt\",\n",
    "                        \"file_id\": str(uuid.uuid4()),\n",
    "                        \"source\": \"Dọn dẹp buồng phòng_structured.txt\",\n",
    "                        \"page\": i\n",
    "                    }\n",
    "                }\n",
    "                \n",
    "                self.payloads.append(payload)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"❌ Lỗi xử lý document {i+1}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Bước 2: Upsert từng payload\n",
    "        print(f\"\\n💾 Bắt đầu upsert {len(self.payloads)} payloads...\")\n",
    "        success_count = 0\n",
    "        \n",
    "        for i, payload in enumerate(self.payloads):\n",
    "            try:\n",
    "                success = self.upsert_document(payload)\n",
    "                if success:\n",
    "                    success_count += 1\n",
    "                    print(f\"✅ Upsert {i+1}/{len(self.payloads)} thành công\")\n",
    "                else:\n",
    "                    print(f\"❌ Upsert {i+1}/{len(self.payloads)} thất bại\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Lỗi upsert {i+1}: {e}\")\n",
    "        \n",
    "        print(f\"\\n📊 Hoàn thành: {success_count}/{len(self.payloads)} documents thành công\")\n",
    "        return success_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21390657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Bắt đầu xử lý 3 documents...\n",
      "📄 Processing 1/3: - Giới thiệu chung\n",
      "Dịch vụ Dọn dẹp Buồng phòng của...\n",
      "📄 Processing 2/3: \n",
      "- Hướng dẫn sử dụng\n",
      "Hướng dẫn đặt dịch vụ dọn dẹp...\n",
      "📄 Processing 3/3: \n",
      "- Lưu ý\n",
      "- Được chọn cùng lúc nhiều loại phòng, nh...\n",
      "\n",
      "💾 Bắt đầu upsert 3 payloads...\n",
      "✅ Upsert 1/3 thành công\n",
      "✅ Upsert 2/3 thành công\n",
      "✅ Upsert 3/3 thành công\n",
      "\n",
      "📊 Hoàn thành: 3/3 documents thành công\n"
     ]
    }
   ],
   "source": [
    "# ✅ Đúng\n",
    "pipeline = ProcessingPipeline()\n",
    "result = pipeline.process(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b16331a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Searching: 'Giới thiệu chung về dịch vụ dọn dẹp buồng phòng'\n",
      "✅ Query embedded: 512 dimensions\n",
      "✅ Found 3 results\n",
      "\n",
      "📊 KẾT QUẢ SEARCH (3 documents):\n",
      "============================================================\n",
      "\n",
      "🔸 Kết quả 1:\n",
      "   📊 Score: 0.665\n",
      "   📄 Text: \n",
      "- Hướng dẫn sử dụng\n",
      "Hướng dẫn đặt dịch vụ dọn dẹp buồng phòng\n",
      "Bước 1: Chọn địa chỉ cần đặt lịch\n",
      "Bước 2: Chọn loại hình nhà và loại hình phòng.\n",
      "Bước 3: Chọn số lượng phòng cần dọn dẹp\n",
      "Bước 4: Chọn các...\n",
      "   👤 User: test_user\n",
      "   📁 File: e86f28a6-de5f-4992-9321-f6cad218cf16\n",
      "   📖 Page: 1\n",
      "\n",
      "🔸 Kết quả 2:\n",
      "   📊 Score: 0.623\n",
      "   📄 Text: \n",
      "- Lưu ý\n",
      "- Được chọn cùng lúc nhiều loại phòng, nhưng tối đa là 10 phòng cho mỗi loại phòng.\n",
      "- Mỗi phòng sẽ có thời lượng dọn dẹp khác nhau, nhưng tổng thời lượng công việc tối đa là 6 giờ.\n",
      "- Phụ thu ...\n",
      "   👤 User: test_user\n",
      "   📁 File: d10766e1-2ae9-4a4c-bddb-d96cf2bc94e5\n",
      "   📖 Page: 2\n",
      "\n",
      "🔸 Kết quả 3:\n",
      "   📊 Score: 0.618\n",
      "   📄 Text: - Giới thiệu chung\n",
      "Dịch vụ Dọn dẹp Buồng phòng của bTaskee- Giải pháp dọn dẹp nhanh chóng và tiện lợi cho chủ các hệ thống khách sạn, homestay, căn hộ dịch vụ, villa, nhà nguyên căn. Đăng lịch với 60 ...\n",
      "   👤 User: test_user\n",
      "   📁 File: 9d93dc46-fc85-4802-9f54-75c14d09d58d\n",
      "   📖 Page: 0\n"
     ]
    }
   ],
   "source": [
    "class SearchPipeline:\n",
    "    def __init__(self):\n",
    "        self.embed_url = EMMBED_SERVICE_URL\n",
    "        self.db_url = DATABASE_SERVICE_URL\n",
    "    \n",
    "    def embed_query(self, text: str) -> list:\n",
    "        \"\"\"Convert text to embedding vector\"\"\"\n",
    "        response = requests.post(\n",
    "            f\"{self.embed_url}/embed\", \n",
    "            json={\"text\": text},\n",
    "            timeout=30\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"embedding\"]\n",
    "    \n",
    "    def vector_search(self, query_vector: list, limit: int = 5, score_threshold: float = 0.7):\n",
    "        \"\"\"Search using vector\"\"\"\n",
    "        response = requests.post(\n",
    "            f\"{self.db_url}/search\", \n",
    "            json={\n",
    "                \"query_vector\": query_vector,\n",
    "                \"limit\": limit,\n",
    "                \"score_threshold\": score_threshold\n",
    "            },\n",
    "            timeout=30\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    \n",
    "    def search(self, query_text: str, limit: int = 5, score_threshold: float = 0.7):\n",
    "        \"\"\"End-to-end search from text query\"\"\"\n",
    "        print(f\"🔍 Searching: '{query_text}'\")\n",
    "        \n",
    "        # Embed query\n",
    "        query_vector = self.embed_query(query_text)\n",
    "        print(f\"✅ Query embedded: {len(query_vector)} dimensions\")\n",
    "        \n",
    "        # Search\n",
    "        results = self.vector_search(query_vector, limit, score_threshold)\n",
    "        print(f\"✅ Found {results['total_found']} results\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def display_results(self, results):\n",
    "        \"\"\"Display search results nicely\"\"\"\n",
    "        if not results or not results.get(\"results\"):\n",
    "            print(\"❌ Không tìm thấy kết quả nào\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\n📊 KẾT QUẢ SEARCH ({results['total_found']} documents):\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        for i, result in enumerate(results[\"results\"]):\n",
    "            print(f\"\\n🔸 Kết quả {i+1}:\")\n",
    "            print(f\"   📊 Score: {result['score']:.3f}\")\n",
    "            print(f\"   📄 Text: {result['payload']['text'][:200]}...\")\n",
    "            print(f\"   👤 User: {result['payload'].get('user_id', 'N/A')}\")\n",
    "            print(f\"   📁 File: {result['payload'].get('file_id', 'N/A')}\")\n",
    "            print(f\"   📖 Page: {result['payload'].get('page', 'N/A')}\")\n",
    "\n",
    "# Sử dụng\n",
    "searcher = SearchPipeline()\n",
    "\n",
    "# Test search\n",
    "search_query = \"Giới thiệu chung về dịch vụ dọn dẹp buồng phòng\"\n",
    "results = searcher.search(search_query, limit=3, score_threshold=0.5)\n",
    "searcher.display_results(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3ae1c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "from typing import Dict, List\n",
    "import math\n",
    "\n",
    "class BM25Encoder:\n",
    "    def __init__(self, k1=1.2, b=0.75):\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self.vocabulary = {}\n",
    "        self.doc_freqs = {}\n",
    "        self.idf = {}\n",
    "        self.doc_len = []\n",
    "        self.avgdl = 0\n",
    "        \n",
    "    def tokenize(self, text: str) -> List[str]:\n",
    "        \"\"\"Simple tokenization\"\"\"\n",
    "        # Convert to lowercase and split by non-alphanumeric characters\n",
    "        tokens = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "        return tokens\n",
    "    \n",
    "    def fit(self, corpus: List[str]):\n",
    "        \"\"\"Fit BM25 on corpus\"\"\"\n",
    "        nd = len(corpus)\n",
    "        doc_freqs = {}\n",
    "        \n",
    "        for document in corpus:\n",
    "            tokens = self.tokenize(document)\n",
    "            self.doc_len.append(len(tokens))\n",
    "            \n",
    "            # Count unique tokens in document\n",
    "            unique_tokens = set(tokens)\n",
    "            for token in unique_tokens:\n",
    "                doc_freqs[token] = doc_freqs.get(token, 0) + 1\n",
    "        \n",
    "        self.doc_freqs = doc_freqs\n",
    "        self.avgdl = sum(self.doc_len) / len(self.doc_len)\n",
    "        \n",
    "        # Calculate IDF\n",
    "        for token, freq in doc_freqs.items():\n",
    "            self.idf[token] = math.log((nd - freq + 0.5) / (freq + 0.5))\n",
    "    \n",
    "    def encode(self, text: str) -> Dict[int, float]:\n",
    "        \"\"\"Encode text to sparse vector\"\"\"\n",
    "        tokens = self.tokenize(text)\n",
    "        token_counts = Counter(tokens)\n",
    "        \n",
    "        sparse_vector = {}\n",
    "        \n",
    "        for token, count in token_counts.items():\n",
    "            if token in self.idf:\n",
    "                # Get token index (create vocabulary on the fly)\n",
    "                if token not in self.vocabulary:\n",
    "                    self.vocabulary[token] = len(self.vocabulary)\n",
    "                \n",
    "                token_idx = self.vocabulary[token]\n",
    "                \n",
    "                # BM25 score calculation\n",
    "                idf = self.idf[token]\n",
    "                tf = count\n",
    "                doc_len = len(tokens)\n",
    "                \n",
    "                score = idf * (tf * (self.k1 + 1)) / (tf + self.k1 * (1 - self.b + self.b * doc_len / self.avgdl))\n",
    "                \n",
    "                if score > 0:\n",
    "                    sparse_vector[token_idx] = score\n",
    "        \n",
    "        return sparse_vector\n",
    "\n",
    "# Global BM25 encoder\n",
    "bm25_encoder = BM25Encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34eff12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Bắt đầu xử lý 3 documents với Hybrid Search...\n",
      "🔧 Fitting BM25 on 3 documents...\n",
      "✅ BM25 fitted successfully\n",
      "📄 Processing 1/3: - Giới thiệu chung\n",
      "Dịch vụ Dọn dẹp Buồng phòng của...\n",
      "📄 Processing 2/3: \n",
      "- Hướng dẫn sử dụng\n",
      "Hướng dẫn đặt dịch vụ dọn dẹp...\n",
      "📄 Processing 3/3: \n",
      "- Lưu ý\n",
      "- Được chọn cùng lúc nhiều loại phòng, nh...\n",
      "\n",
      "💾 Bắt đầu upsert 3 payloads...\n",
      "🔄 Upsert batch 1: 3 documents...\n",
      "✅ Batch 1 thành công (3 documents)\n",
      "\n",
      "📊 Hoàn thành: 3/3 documents thành công\n"
     ]
    }
   ],
   "source": [
    "class HybridProcessingPipeline:\n",
    "    def __init__(self, batch_size=5):\n",
    "        self.documents = []\n",
    "        self.payloads = []\n",
    "        self.batch_size = batch_size\n",
    "        self.bm25_encoder = BM25Encoder()\n",
    "        self.corpus_fitted = False\n",
    "    \n",
    "    def embed_text(self, text: str) -> list:\n",
    "        \"\"\"Get dense embedding\"\"\"\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                EMMBED_SERVICE_URL + \"/embed\", \n",
    "                json={\"text\": text},\n",
    "                timeout=30\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            return response.json()[\"embedding\"]\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Lỗi embed: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def create_sparse_vector(self, text: str) -> Dict[int, float]:\n",
    "        \"\"\"Create BM25 sparse vector\"\"\"\n",
    "        if not self.corpus_fitted:\n",
    "            print(\"⚠️ BM25 chưa được fit trên corpus\")\n",
    "            return {}\n",
    "        \n",
    "        return self.bm25_encoder.encode(text)\n",
    "    \n",
    "    def fit_bm25(self, corpus: List[str]):\n",
    "        \"\"\"Fit BM25 on the corpus\"\"\"\n",
    "        print(f\"🔧 Fitting BM25 on {len(corpus)} documents...\")\n",
    "        self.bm25_encoder.fit(corpus)\n",
    "        self.corpus_fitted = True\n",
    "        print(\"✅ BM25 fitted successfully\")\n",
    "    \n",
    "    def upsert_batch(self, payloads_batch: list) -> bool:\n",
    "        \"\"\"Upsert batch với hybrid vectors\"\"\"\n",
    "        try:\n",
    "            request_data = {\"points\": payloads_batch}\n",
    "            \n",
    "            response = requests.post(\n",
    "                DATABASE_SERVICE_URL + \"/upsert\", \n",
    "                json=request_data,\n",
    "                timeout=60\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            return response.json().get(\"success\", False)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Lỗi upsert batch: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def process(self, data):\n",
    "        print(f\"🚀 Bắt đầu xử lý {len(data)} documents với Hybrid Search...\")\n",
    "        \n",
    "        # Bước 1: Fit BM25 trên toàn bộ corpus\n",
    "        corpus = [str(doc) for doc in data]\n",
    "        self.fit_bm25(corpus)\n",
    "        \n",
    "        # Bước 2: Tạo embeddings và sparse vectors\n",
    "        for i, document in enumerate(data):\n",
    "            try:\n",
    "                print(f\"📄 Processing {i+1}/{len(data)}: {str(document)[:50]}...\")\n",
    "                \n",
    "                # Dense embedding\n",
    "                dense_vector = self.embed_text(str(document))\n",
    "                \n",
    "                # Sparse vector (BM25)\n",
    "                sparse_vector = self.create_sparse_vector(str(document))\n",
    "                \n",
    "                # Tạo payload với cả 2 loại vector\n",
    "                payload = {\n",
    "                    \"id\": str(uuid.uuid4()),\n",
    "                    \"vector\": {\n",
    "                        \"dense_vector\": dense_vector,\n",
    "                        \"bm25_sparse_vector\": {\n",
    "                            \"indices\": list(sparse_vector.keys()),\n",
    "                            \"values\": list(sparse_vector.values())\n",
    "                        }\n",
    "                    },\n",
    "                    \"payload\": {\n",
    "                        \"text\": str(document),\n",
    "                        \"user_id\": \"test_user\",\n",
    "                        \"title\": \"Test Title\",\n",
    "                        \"file_id\": \"test_file_123\",\n",
    "                        \"source\": str(uuid.uuid4()),\n",
    "                        \"page\": 1\n",
    "                    }\n",
    "                }\n",
    "                \n",
    "                self.payloads.append(payload)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"❌ Lỗi xử lý document {i+1}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Bước 3: Upsert theo batch\n",
    "        print(f\"\\n💾 Bắt đầu upsert {len(self.payloads)} payloads...\")\n",
    "        success_count = 0\n",
    "        \n",
    "        for i in range(0, len(self.payloads), self.batch_size):\n",
    "            batch = self.payloads[i:i + self.batch_size]\n",
    "            batch_num = i // self.batch_size + 1\n",
    "            \n",
    "            try:\n",
    "                print(f\"🔄 Upsert batch {batch_num}: {len(batch)} documents...\")\n",
    "                success = self.upsert_batch(batch)\n",
    "                \n",
    "                if success:\n",
    "                    success_count += len(batch)\n",
    "                    print(f\"✅ Batch {batch_num} thành công ({len(batch)} documents)\")\n",
    "                else:\n",
    "                    print(f\"❌ Batch {batch_num} thất bại\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"❌ Lỗi upsert batch {batch_num}: {e}\")\n",
    "        \n",
    "        print(f\"\\n📊 Hoàn thành: {success_count}/{len(self.payloads)} documents thành công\")\n",
    "        return success_count\n",
    "\n",
    "# Sử dụng\n",
    "hybrid_pipeline = HybridProcessingPipeline()\n",
    "result = hybrid_pipeline.process(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e164bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "🔍 Hybrid Search: 'Giới thiệu chung về dịch vụ dọn dẹp buồng phòng'\n",
      "   📊 Dense weight: 0.7, Sparse weight: 0.3\n",
      "⚠️ BM25 chưa được fit. Chỉ sử dụng dense search.\n",
      "❌ Lỗi hybrid search: 422 Client Error: Unprocessable Entity for url: http://localhost:8002/search\n",
      "🔄 Fallback to dense search...\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "🔍 Hybrid Search: 'quy trình dọn dẹp'\n",
      "   📊 Dense weight: 0.7, Sparse weight: 0.3\n",
      "⚠️ BM25 chưa được fit. Chỉ sử dụng dense search.\n",
      "❌ Lỗi hybrid search: 422 Client Error: Unprocessable Entity for url: http://localhost:8002/search\n",
      "🔄 Fallback to dense search...\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "🔍 Hybrid Search: 'thiết bị an toàn'\n",
      "   📊 Dense weight: 0.7, Sparse weight: 0.3\n",
      "⚠️ BM25 chưa được fit. Chỉ sử dụng dense search.\n",
      "❌ Lỗi hybrid search: 422 Client Error: Unprocessable Entity for url: http://localhost:8002/search\n",
      "🔄 Fallback to dense search...\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "🔍 Hybrid Search: 'hướng dẫn sử dụng'\n",
      "   📊 Dense weight: 0.7, Sparse weight: 0.3\n",
      "⚠️ BM25 chưa được fit. Chỉ sử dụng dense search.\n",
      "❌ Lỗi hybrid search: 422 Client Error: Unprocessable Entity for url: http://localhost:8002/search\n",
      "🔄 Fallback to dense search...\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "class HybridSearcher:\n",
    "    def __init__(self):\n",
    "        self.embed_url = EMMBED_SERVICE_URL\n",
    "        self.db_url = DATABASE_SERVICE_URL\n",
    "        self.bm25_encoder = BM25Encoder()\n",
    "        self.corpus_fitted = False\n",
    "    \n",
    "    def fit_bm25(self, corpus: List[str]):\n",
    "        \"\"\"Fit BM25 for search\"\"\"\n",
    "        self.bm25_encoder.fit(corpus)\n",
    "        self.corpus_fitted = True\n",
    "    \n",
    "    def embed_query(self, text: str) -> list:\n",
    "        \"\"\"Get dense embedding for query\"\"\"\n",
    "        response = requests.post(\n",
    "            f\"{self.embed_url}/embed\", \n",
    "            json={\"text\": text},\n",
    "            timeout=30\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"embedding\"]\n",
    "    \n",
    "    def create_query_sparse_vector(self, text: str) -> Dict[int, float]:\n",
    "        \"\"\"Create sparse vector for query\"\"\"\n",
    "        if not self.corpus_fitted:\n",
    "            print(\"⚠️ BM25 chưa được fit. Chỉ sử dụng dense search.\")\n",
    "            return {}\n",
    "        return self.bm25_encoder.encode(text)\n",
    "    \n",
    "    def hybrid_search(self, \n",
    "                     query_text: str, \n",
    "                     limit: int = 5, \n",
    "                     dense_weight: float = 0.7,\n",
    "                     sparse_weight: float = 0.3):\n",
    "        \"\"\"\n",
    "        Hybrid search kết hợp dense và sparse vectors\n",
    "        \n",
    "        Args:\n",
    "            query_text: Text query\n",
    "            limit: Số kết quả trả về\n",
    "            dense_weight: Trọng số cho semantic search (0-1)\n",
    "            sparse_weight: Trọng số cho keyword search (0-1)\n",
    "        \"\"\"\n",
    "        print(f\"🔍 Hybrid Search: '{query_text}'\")\n",
    "        print(f\"   📊 Dense weight: {dense_weight}, Sparse weight: {sparse_weight}\")\n",
    "        \n",
    "        try:\n",
    "            # 1. Tạo dense vector\n",
    "            dense_vector = self.embed_query(query_text)\n",
    "            \n",
    "            # 2. Tạo sparse vector\n",
    "            sparse_vector = self.create_query_sparse_vector(query_text)\n",
    "            \n",
    "            # 3. Chuẩn bị query cho Qdrant\n",
    "            if sparse_vector:\n",
    "                # Hybrid search với cả dense và sparse\n",
    "                query_data = {\n",
    "                    \"prefetch\": [\n",
    "                        {\n",
    "                            \"query\": dense_vector,\n",
    "                            \"using\": \"dense_vector\",\n",
    "                            \"limit\": limit * 2  # Lấy nhiều hơn để fusion\n",
    "                        },\n",
    "                        {\n",
    "                            \"query\": {\n",
    "                                \"indices\": list(sparse_vector.keys()),\n",
    "                                \"values\": list(sparse_vector.values())\n",
    "                            },\n",
    "                            \"using\": \"bm25_sparse_vector\", \n",
    "                            \"limit\": limit * 2\n",
    "                        }\n",
    "                    ],\n",
    "                    \"query\": {\n",
    "                        \"fusion\": \"rrf\"  # Reciprocal Rank Fusion\n",
    "                    },\n",
    "                    \"limit\": limit\n",
    "                }\n",
    "            else:\n",
    "                # Chỉ dense search\n",
    "                query_data = {\n",
    "                    \"query\": dense_vector,\n",
    "                    \"using\": \"dense_vector\",\n",
    "                    \"limit\": limit\n",
    "                }\n",
    "            \n",
    "            # 4. Gửi request\n",
    "            response = requests.post(\n",
    "                f\"{self.db_url}/search\",\n",
    "                json=query_data,\n",
    "                timeout=30\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            results = response.json()\n",
    "            \n",
    "            # 5. Display results\n",
    "            self.display_hybrid_results(results, query_text)\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Lỗi hybrid search: {e}\")\n",
    "            # Fallback to simple dense search\n",
    "            return self.fallback_dense_search(query_text, limit)\n",
    "    \n",
    "    def fallback_dense_search(self, query_text: str, limit: int):\n",
    "        \"\"\"Fallback to simple dense search\"\"\"\n",
    "        print(\"🔄 Fallback to dense search...\")\n",
    "        \n",
    "        dense_vector = self.embed_query(query_text)\n",
    "        \n",
    "        response = requests.post(\n",
    "            f\"{self.db_url}/search\",\n",
    "            json={\n",
    "                \"query_vector\": dense_vector,\n",
    "                \"limit\": limit,\n",
    "                \"score_threshold\": 0.5\n",
    "            },\n",
    "            timeout=30\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    \n",
    "    def display_hybrid_results(self, results, query_text):\n",
    "        \"\"\"Display hybrid search results\"\"\"\n",
    "        if not results or not results.get(\"results\"):\n",
    "            print(\"❌ Không tìm thấy kết quả nào\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\n🎯 HYBRID SEARCH RESULTS cho: '{query_text}'\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        for i, result in enumerate(results[\"results\"]):\n",
    "            print(f\"\\n🔸 Kết quả {i+1}:\")\n",
    "            print(f\"   📊 Hybrid Score: {result['score']:.3f}\")\n",
    "            print(f\"   📄 Text: {result['payload']['text'][:200]}...\")\n",
    "            print(f\"   👤 User: {result['payload'].get('user_id', 'N/A')}\")\n",
    "            print(f\"   📁 File: {result['payload'].get('file_id', 'N/A')}\")\n",
    "\n",
    "# Sử dụng Hybrid Search\n",
    "searcher = HybridSearcher()\n",
    "\n",
    "# Nếu bạn có corpus để fit BM25\n",
    "# searcher.fit_bm25(data)  # Fit trên corpus đã upsert\n",
    "\n",
    "# Test hybrid search\n",
    "test_queries = [\n",
    "    \"Giới thiệu chung về dịch vụ dọn dẹp buồng phòng\",\n",
    "    \"quy trình dọn dẹp\",\n",
    "    \"thiết bị an toàn\",\n",
    "    \"hướng dẫn sử dụng\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    results = searcher.hybrid_search(\n",
    "        query, \n",
    "        limit=3, \n",
    "        dense_weight=0.7,  # 70% semantic\n",
    "        sparse_weight=0.3  # 30% keyword\n",
    "    )\n",
    "    print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72c81f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Bắt đầu xử lý 3 documents với Hybrid Search...\n",
      "🔧 Fitting BM25 on 3 documents...\n",
      "✅ BM25 fitted successfully\n",
      "📄 Processing 1/3: - Giới thiệu chung\n",
      "Dịch vụ Dọn dẹp Buồng phòng của...\n",
      "📄 Processing 2/3: \n",
      "- Hướng dẫn sử dụng\n",
      "Hướng dẫn đặt dịch vụ dọn dẹp...\n",
      "📄 Processing 3/3: \n",
      "- Lưu ý\n",
      "- Được chọn cùng lúc nhiều loại phòng, nh...\n",
      "\n",
      "💾 Bắt đầu upsert 3 payloads...\n",
      "🔄 Upsert batch 1: 3 documents...\n",
      "✅ Batch 1 thành công (3 documents)\n",
      "\n",
      "📊 Hoàn thành: 3/3 documents thành công\n",
      "🔍 Hybrid Search: 'Giới thiệu chung về dịch vụ dọn dẹp buồng phòng'\n",
      "   📊 Dense weight: 0.7, Sparse weight: 0.3\n",
      "❌ Lỗi hybrid search: 422 Client Error: Unprocessable Entity for url: http://localhost:8002/search\n",
      "🔄 Fallback to dense search...\n"
     ]
    }
   ],
   "source": [
    "# 1. Upsert data với hybrid vectors\n",
    "hybrid_pipeline = HybridProcessingPipeline()\n",
    "hybrid_pipeline.process(data)\n",
    "\n",
    "# 2. Search với hybrid\n",
    "searcher = HybridSearcher()\n",
    "searcher.fit_bm25(data)  # Fit BM25 trên corpus\n",
    "\n",
    "# 3. Test search\n",
    "results = searcher.hybrid_search(\n",
    "    \"Giới thiệu chung về dịch vụ dọn dẹp buồng phòng\",\n",
    "    limit=5,\n",
    "    dense_weight=0.7,   # 70% semantic similarity\n",
    "    sparse_weight=0.3   # 30% keyword matching\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab2e053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d742e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
