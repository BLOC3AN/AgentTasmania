#!/usr/bin/env python3
"""
Example usage cá»§a DocxDataProcessor
Demo cÃ¡c tÃ­nh nÄƒng chÃ­nh vÃ  cÃ¡ch sá»­ dá»¥ng
"""

import os
import sys
import time
from pathlib import Path

# Add current directory to path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from docx_data_processor import DocxDataProcessor


def check_services():
    """Kiá»ƒm tra cÃ¡c service cÃ³ hoáº¡t Ä‘á»™ng khÃ´ng"""
    import requests
    
    services = {
        "Embedding Service": "http://localhost:8005/health",
        "Database Service": "http://localhost:8002/health"
    }
    
    print("ğŸ” Checking services...")
    all_ok = True
    
    for name, url in services.items():
        try:
            response = requests.get(url, timeout=5)
            if response.status_code == 200:
                print(f"âœ… {name}: OK")
            else:
                print(f"âŒ {name}: HTTP {response.status_code}")
                all_ok = False
        except Exception as e:
            print(f"âŒ {name}: {e}")
            all_ok = False
    
    return all_ok


def example_basic_usage():
    """Example cÆ¡ báº£n: xá»­ lÃ½ má»™t file"""
    print("\n" + "="*50)
    print("ğŸ“„ EXAMPLE 1: Basic File Processing")
    print("="*50)
    
    # Initialize processor
    processor = DocxDataProcessor(
        embed_service_url="http://localhost:8005",
        database_service_url="http://localhost:8002",
        chunk_size=1500,
        chunk_overlap=50
    )
    
    # File path
    file_path = "./data/Module 6 S2 2025.docx"
    
    if not Path(file_path).exists():
        print(f"âš ï¸ File khÃ´ng tá»“n táº¡i: {file_path}")
        print("ğŸ’¡ Táº¡o file test hoáº·c cáº­p nháº­t Ä‘Æ°á»ng dáº«n")
        return
    
    print(f"ğŸš€ Processing file: {file_path}")
    start_time = time.time()
    
    # Process file
    result = processor.process_file(file_path)
    
    end_time = time.time()
    processing_time = end_time - start_time
    
    # Show results
    print(f"\nğŸ“Š Results:")
    print(f"â±ï¸ Processing time: {processing_time:.2f} seconds")
    
    if result["success"]:
        print(f"âœ… Success: {result['successful_chunks']}/{result['total_chunks']} chunks")
        print(f"ğŸ“‹ Metadata: {result['metadata']}")
    else:
        print(f"âŒ Failed: {result['error']}")
    
    # Show stats
    stats = processor.get_stats()
    print(f"\nğŸ“ˆ Processor Stats:")
    for key, value in stats.items():
        print(f"  {key}: {value}")


def example_directory_processing():
    """Example: xá»­ lÃ½ táº¥t cáº£ file trong thÆ° má»¥c"""
    print("\n" + "="*50)
    print("ğŸ“ EXAMPLE 2: Directory Processing")
    print("="*50)
    
    processor = DocxDataProcessor(chunk_size=400)
    
    data_dir = "./data"
    if not Path(data_dir).exists():
        print(f"âš ï¸ ThÆ° má»¥c khÃ´ng tá»“n táº¡i: {data_dir}")
        return
    
    print(f"ğŸš€ Processing directory: {data_dir}")
    start_time = time.time()
    
    results = processor.process_directory(data_dir)
    
    end_time = time.time()
    processing_time = end_time - start_time
    
    print(f"\nğŸ“Š Directory Results:")
    print(f"â±ï¸ Total processing time: {processing_time:.2f} seconds")
    print(f"ğŸ“„ Files processed: {len(results)}")
    
    successful_files = sum(1 for r in results if r["success"])
    print(f"âœ… Successful: {successful_files}/{len(results)} files")
    
    # Detail per file
    for result in results:
        if result["success"]:
            print(f"  âœ… {Path(result['file_path']).name}: {result['successful_chunks']} chunks")
        else:
            print(f"  âŒ {Path(result['file_path']).name}: {result['error']}")
    
    # Overall stats
    stats = processor.get_stats()
    print(f"\nğŸ“ˆ Overall Stats:")
    for key, value in stats.items():
        print(f"  {key}: {value}")


def example_text_cleaning():
    """Example: demo text cleaning"""
    print("\n" + "="*50)
    print("ğŸ§¹ EXAMPLE 3: Text Cleaning Demo")
    print("="*50)
    
    processor = DocxDataProcessor()
    
    # Sample dirty text
    dirty_texts = [
        "  Hello   world  \n\n\n  This is   a test  \n\n  ",
        "Text\twith\ttabs\nand\r\ncarriage\rreturns",
        "\n\n\n   Multiple   \n\n   newlines   \n\n\n",
        "Normal text without issues"
    ]
    
    for i, dirty_text in enumerate(dirty_texts, 1):
        print(f"\nğŸ§ª Test {i}:")
        print(f"ğŸ“ Original: {repr(dirty_text)}")
        
        cleaned = processor.clean_text(dirty_text)
        print(f"âœ¨ Cleaned:  {repr(cleaned)}")
        
        print(f"ğŸ“ Length: {len(dirty_text)} â†’ {len(cleaned)}")


def example_metadata_extraction():
    """Example: demo metadata extraction"""
    print("\n" + "="*50)
    print("ğŸ“‹ EXAMPLE 4: Metadata Extraction Demo")
    print("="*50)
    
    processor = DocxDataProcessor()
    
    # Sample filenames
    filenames = [
        "Module 6 S2 2025.docx",
        "math_week06_S2025.txt",
        "Week 3 Assignment.docx",
        "random_document.pdf",
        "Module 12 Final Project S1 2024.docx"
    ]
    
    for filename in filenames:
        print(f"\nğŸ“„ File: {filename}")
        metadata = processor.extract_metadata(filename)
        
        for key, value in metadata.items():
            print(f"  {key}: {value}")


def example_chunking():
    """Example: demo text chunking"""
    print("\n" + "="*50)
    print("âœ‚ï¸ EXAMPLE 5: Text Chunking Demo")
    print("="*50)
    
    # Test different chunk sizes
    chunk_sizes = [100, 200, 500]
    
    sample_text = """
    Welcome to Module 6 Writing in Practice. This module covers academic writing skills 
    including source integration, APA referencing, and critical reading. Learning outcomes 
    include effective communication and source evaluation. Students will learn to integrate 
    sources into their writing using various methods such as direct quotes, paraphrasing, 
    summarizing, and synthesizing. The module emphasizes the importance of proper citation 
    and reference formatting according to APA style guidelines.
    """ * 3  # Repeat to make it longer
    
    print(f"ğŸ“ Sample text length: {len(sample_text)} characters")
    
    for chunk_size in chunk_sizes:
        processor = DocxDataProcessor(chunk_size=chunk_size, chunk_overlap=20)
        chunks = processor.chunk_text(sample_text)
        
        print(f"\nâœ‚ï¸ Chunk size {chunk_size}:")
        print(f"  ğŸ“Š Number of chunks: {len(chunks)}")
        
        for i, chunk in enumerate(chunks[:3]):  # Show first 3 chunks
            print(f"  ğŸ“„ Chunk {i+1}: {len(chunk)} chars - {chunk[:50]}...")
        
        if len(chunks) > 3:
            print(f"  ... and {len(chunks) - 3} more chunks")


def example_offline_processing():
    """Example: xá»­ lÃ½ offline (khÃ´ng gá»i API)"""
    print("\n" + "="*50)
    print("ğŸ”Œ EXAMPLE 6: Offline Processing (No API calls)")
    print("="*50)
    
    processor = DocxDataProcessor()
    
    file_path = "./data/Module 6 S2 2025.docx"
    
    if not Path(file_path).exists():
        print(f"âš ï¸ File khÃ´ng tá»“n táº¡i: {file_path}")
        return
    
    try:
        print(f"ğŸ“„ Loading file: {file_path}")
        
        # 1. Load content
        content = processor.load_docx(file_path)
        print(f"âœ… Loaded: {len(content)} characters")
        
        # 2. Clean text
        cleaned = processor.clean_text(content)
        print(f"âœ… Cleaned: {len(cleaned)} characters")
        
        # 3. Extract metadata
        metadata = processor.extract_metadata(file_path)
        print(f"âœ… Metadata: {metadata}")
        
        # 4. Chunk text
        chunks = processor.chunk_text(cleaned)
        print(f"âœ… Chunks: {len(chunks)} pieces")

        # 5. Build BM25 corpus if enabled
        if processor.enable_bm25:
            print(f"ğŸ” Building BM25 corpus for sparse vectors...")
            processor.build_bm25_corpus(chunks)
            if processor.bm25_encoder and processor.bm25_encoder.corpus_stats_ready:
                corpus_info = processor.bm25_encoder.get_corpus_info()
                print(f"âœ… BM25 corpus built: {corpus_info['vocabulary_size']} terms")

        # 6. Show sample chunks
        print(f"\nğŸ“„ Sample chunks:")
        for i, chunk in enumerate(chunks[:3]):
            print(f"  Chunk {i+1} ({len(chunk)} chars): {chunk[:100]}...")

        # 7. Create sample payloads (without embedding)
        print(f"\nğŸ“¦ Sample payloads:")
        for i in range(min(2, len(chunks))):
            payload = processor.create_payload(chunks[i], metadata, i)
            payload["vector"] = [0.1] * 512  # Dummy vector

            print(f"  Payload {i+1}:")
            print(f"    ID: {payload['id']}")
            print(f"    Vector dims: {len(payload['vector'])}")
            print(f"    Has sparse vector: {bool(payload.get('sparse_vector'))}")
            if payload.get('sparse_vector'):
                sparse = payload['sparse_vector']
                print(f"    Sparse vector terms: {len(sparse.get('indices', []))}")
            print(f"    Content preview: {payload['payload']['content'][:50]}...")
        
    except Exception as e:
        print(f"âŒ Error: {e}")


def main():
    """Main function Ä‘á»ƒ cháº¡y táº¥t cáº£ examples"""
    print("ğŸš€ DocxDataProcessor Examples")
    print("="*60)
    
    # Check if services are running
    services_ok = check_services()
    
    if not services_ok:
        print("\nâš ï¸ Some services are not running!")
        print("ğŸ’¡ Start services with: docker-compose up embedding vectordb")
        print("ğŸ”Œ Running offline examples only...")
        
        # Run offline examples
        example_text_cleaning()
        example_metadata_extraction()
        example_chunking()
        example_offline_processing()
        
    else:
        print("\nâœ… All services are running!")
        print("ğŸš€ Running full examples...")
        
        # Run all examples
        example_text_cleaning()
        example_metadata_extraction()
        example_chunking()
        example_offline_processing()
        example_basic_usage()
        example_directory_processing()
    
    print("\n" + "="*60)
    print("âœ… Examples completed!")
    print("ğŸ’¡ Check the code in example_usage.py for implementation details")


if __name__ == "__main__":
    main()
